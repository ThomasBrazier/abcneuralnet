% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/explain.R
\name{explain}
\alias{explain}
\title{An \code{explain} object for feature attribution
A R6 class object}
\value{
an \code{explain} object
}
\description{
This module function allows the used to apply a diverse set of explainability methods on a fitted \code{abcnn} neural network
and a given observed dataset, in order to compute the weight of each summary statistic on predictions.
Summary statistics with the higher weight (or importance) are those contributing the most to the prediction.

This feature importance method is useful to perform feature selection (removing summary statistics that don't explain well the output)
and to interpret properly the output of the model.
}
\details{
All the methods used in explain are implemented in the \code{innsight} R package, that is part of the R torch ecosystem.

See \verb{https://bips-hb.github.io/innsight/} for details.
}
\section{Slots}{

\describe{
\item{\code{converter}}{Stores the \code{innsight::converter} object}

\item{\code{result}}{stores results of the \code{explain$run()} method.}

\item{\code{model_method}}{method of the trained neural network (e.g. "concrete dropout")}

\item{\code{variables}}{names of the variables (summary statistics)}

\item{\code{parameters}}{names of the parameter to infer}

\item{\code{ensemble_num_model}}{index of the model when the network is a deep ensemble}

\item{\code{scale_input}}{the \code{abcnn$scale_input} slot from the \code{abcnn} input object}

\item{\code{input_summary}}{the \code{abcnn$input_summary} slot from the \code{abcnn} input object}
}}

\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{x}}{an \code{abcnn} object}

\item{\code{method}}{the \code{innsight} method to apply}

\item{\code{converter}}{the torch/luz model converted to an \code{innsight} object}

\item{\code{result}}{the result of the explainability method}

\item{\code{model_method}}{the method in the \code{abcnn} object}

\item{\code{variables}}{names of the variables (input dimensions)}

\item{\code{parameters}}{names of the parameters to estimate (output dimensions)}

\item{\code{ensemble_num_model}}{index of the model to explain in Deep Ensemble (default is first model)}

\item{\code{scale_input}}{method used to scale input dimensions}

\item{\code{input_summary}}{summary statistics for the input scaling method}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-explain-new}{\code{explain$new()}}
\item \href{#method-explain-print}{\code{explain$print()}}
\item \href{#method-explain-run}{\code{explain$run()}}
\item \href{#method-explain-get_result}{\code{explain$get_result()}}
\item \href{#method-explain-plot}{\code{explain$plot()}}
\item \href{#method-explain-plot_global}{\code{explain$plot_global()}}
\item \href{#method-explain-boxplot}{\code{explain$boxplot()}}
\item \href{#method-explain-clone}{\code{explain$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-new"></a>}}
\if{latex}{\out{\hypertarget{method-explain-new}{}}}
\subsection{Method \code{new()}}{
Create a new \code{explain} object
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$new(x, method = "cw", ensemble_num_model = 1)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{an \code{abcnn} model}

\item{\code{method}}{the explainability method to use (see \code{innsight} for details) (defauls is \code{cw})}

\item{\code{ensemble_num_model}}{index of the model to explain in Deep Ensemble (default is first model)}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-print"></a>}}
\if{latex}{\out{\hypertarget{method-explain-print}{}}}
\subsection{Method \code{print()}}{
Print the converter
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$print()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-run"></a>}}
\if{latex}{\out{\hypertarget{method-explain-run}{}}}
\subsection{Method \code{run()}}{
Apply the \code{method} to the passed \code{data} to be explained

The method is run on a \code{data} object (see \code{innsight} manual)
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$run(data, data_ref = NULL, method = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data}}{(array, data.frame, torch_tensor or list)
The data to which the method is to be applied. These must have the same format as the input data of the passed model to the converter object. This means either
an array, data.frame, torch_tensor or array-like format of size (batch_size, dim_in), if e.g., the model has only one input layer, or
a list with the corresponding input data (according to the upper point) for each of the input layers.

Note: For the model-agnostic methods, only models with a single input and output layer is allowed!}

\item{\code{data_ref}}{(array, data.frame or torch_tensor)
The dataset to which the method is to be applied. These must have the same format as the input data of the passed model and has to be either matrix, an array, a data.frame or a torch_tensor.
Note: For the model-agnostic methods, only models with a single input and output layer is allowed!}

\item{\code{method}}{The method to run. Change the method specified in \code{new()}}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-get_result"></a>}}
\if{latex}{\out{\hypertarget{method-explain-get_result}{}}}
\subsection{Method \code{get_result()}}{
Get the results of the Feature Attribution method
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$get_result(type = "array")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{type}}{the results can be returned as an \code{array}, \code{data.frame}, or \code{torch_tensor}}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
Note that when the \code{abcnn} model is \code{tabnet-abc}, \code{get_result()} returns importances weigths of the fitted model.
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-plot"></a>}}
\if{latex}{\out{\hypertarget{method-explain-plot}{}}}
\subsection{Method \code{plot()}}{
Plot the results of the Feature Attribution method
for single data points
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$plot(as_plotly = FALSE, type = "mask_agg", output_label = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{as_plotly}}{If \code{TRUE}, plot the figure as a plotly object (default = \code{FALSE})}

\item{\code{type}}{a character value. Passed to the Tabnet autoplot method. Either \code{mask_agg} the default, for a single heatmap of aggregated mask importance per predictor along the dataset, or \code{steps} for one heatmap at each mask step.}

\item{\code{output_label}}{character, the names of the variables to plot (if NULL, all variables are plotted)}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
Note that when the \code{abcnn} model is \code{tabnet-abc}, \code{plot()} returns the \code{autoplot()} function on the results of the \code{tabnet} model.
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-plot_global"></a>}}
\if{latex}{\out{\hypertarget{method-explain-plot_global}{}}}
\subsection{Method \code{plot_global()}}{
Plot the results of the Feature Attribution method for the global dataset
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$plot_global(as_plotly = FALSE, output_label = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{as_plotly}}{If \code{TRUE}, plot the figure as a plotly object (default = \code{FALSE})}

\item{\code{output_label}}{character, the names of the variables to plot (if NULL, all variables are plotted)}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-boxplot"></a>}}
\if{latex}{\out{\hypertarget{method-explain-boxplot}{}}}
\subsection{Method \code{boxplot()}}{
Alias for \code{plot_global} for tabular and signal data
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$boxplot(as_plotly = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{as_plotly}}{If \code{TRUE}, plot the figure as a plotly object (default = \code{FALSE})}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-explain-clone"></a>}}
\if{latex}{\out{\hypertarget{method-explain-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{explain$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
