---
title: "model_inference"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{model_inference}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(abcneuralnet)
library(ggplot2)
library(torch)
```


## Principles of ABC inference



## Make a toy dataset

Two parameters to estimate.

Simulate two different functions (sin and cos), with missing data (gaps) and different amounts of random noise in the two parts of the dataset.

```{r, echo = T}
# Parameters of simulated input x
data_range = 7
data_step = 0.001

# Boundaries of the gap in the data range
bound1 = -2
bound2 = 2

# Random noise applied on y
data_sigma1 = 0.1
data_sigma2 = 0.5

# Number of simulated data points
# num_data = 10000

# Simulate x1
data_x1a = seq(-data_range, bound1 + data_step, by = data_step)
data_x1b = seq(bound2, data_range + data_step, by = data_step)
# Simulate targets y
data_y1a = sin(data_x1a) + rnorm(length(data_x1a), 0, data_sigma1)
data_y1b = sin(data_x1b) + rnorm(length(data_x1b), 0, data_sigma2)

# Shift X1 to get X2
data_x2a = data_x1a + 7
data_x2b = data_x1b + 7
# Simulate targets y
data_y2a = cos(data_x2a) + rnorm(length(data_x2a), 0, data_sigma1)
data_y2b = cos(data_x2b) + rnorm(length(data_x2b), 0, data_sigma2)

df = data.frame(x1 = c(data_x1a, data_x1b),
                    x2 = c(data_x2a, data_x2b),
                    y1 = c(data_y1a, data_y1b),
                    y2 = c(data_y2a, data_y2b))

# Shuffle data
shuffle_idx = sample(1:(nrow(df)), nrow(df), replace = FALSE)
df_train = df[shuffle_idx,]

# Train/Test datasets
# test_ratio = 0.1
# num_train_data = round(nrow(df) * (1 - test_ratio), digits = 0)
# num_test_data  = nrow(df) - num_train_data
# 
# train_x = df[1:num_train_data, c("x1", "x2")]
# train_y = df[1:num_train_data, c("y1", "y2")]
# test_x = df[num_train_data:nrow(df_train), c("x1", "x2")]
# test_y = df[num_train_data:nrow(df_train), c("y1", "y2")]
train_x = df_train[, c("x1", "x2")]
train_y = df_train[, c("y1", "y2")]


# Make a pseudo-obseerved dataset with out of distribution data points
# Simulate x1
data_x1 = seq(-data_range, data_range, length.out = 1000)
# Simulate true targets y
data_y1 = sin(data_x1)

# Shift X1 to get X2
data_x2 = data_x1 + 7
# Simulate targets y
data_y2 = cos(data_x2)

df_observed = data.frame(x1 = data_x1,
                x2 = data_x2,
                y1 = data_y1,
                y2 = data_y2)


observed_x  = df_observed[, c("x1", "x2")]
observed_y  = df_observed[, c("y1", "y2")]
```


```{r, echo = F}
# Plot the simulated data
p1 = ggplot(data = df_train, aes(x = x1, y = y1)) +
  geom_point(color = "Blue", alpha = 0.2) +
  geom_line(data = df_observed, aes(x = x1, y = y1), color = "red") +
  theme_bw()

p2 = ggplot(data = df_train, aes(x = x2, y = y2)) +
  geom_point(color = "Green", alpha = 0.2) +
  geom_line(data = df_observed, aes(x = x2, y = y2), color = "red") +
  theme_bw()

ggpubr::ggarrange(p1, p2, ncol = 2)
```



## Fit a model with `abcnn`

We use a Concrete Dropout regression model described in [ref].

```{r, echo = T}
# Predict Y when X is observed
theta = train_y
sumstats = train_x
observed = observed_x

# Init an abcnn object with inputs and targets
abc = abcnn$new(theta,
            sumstats,
            observed,
            method = 'concrete dropout',
            num_hidden_layers = 3,
            num_hidden_dim = 256,
            epochs = 10)


# abc$summary()

# Plot simulation distribution and observed data points
# abc$plot_lda()
```

The `abcnn` object is a `R6Class` object.
Modern implementation, OOP


For example, the model can be accessed with `abc$model`.


The model is trained by calling `abc$fit()`.


```{r, echo = T}
# Use the fit() method to train the neural network
abc$fit()
```

Don't worry, sometimes the loss can be negative. It is normal and does not impact the training procedure.

Check model fit.

```{r, echo = T}
# Check the fit of the model
as.numeric(unlist(abc$fitted$records$metrics$train))
as.numeric(unlist(abc$fitted$records$metrics$valid))
abc$eval_metrics
```



Plot the training curve. The black horizontal line is the loss computed on the test dataset.


```{r, echo = T}
train_metric = as.numeric(unlist(abc$fitted$records$metrics$train))
valid_metric = as.numeric(unlist(abc$fitted$records$metrics$valid))
eval = abc$eval_metrics$value


train_eval = data.frame(Epoch = rep(1:length(train_metric), 2),
                        Metric = c(train_metric, valid_metric),
                        Mode = c(rep("train", length(train_metric)), rep("validation", length(valid_metric))))

ggplot(train_eval, aes(x = Epoch, y = Metric, color = Mode, fill = Mode)) +
  geom_point() +
  geom_line() +
  xlab("Epoch") + ylab("Loss") +
  geom_hline(yintercept = eval) +
  theme_bw()
```



```{r, echo = T}
abc$plot_training()
```






## Parameter inference from observed summary statistics


After the model is trained, parameter estimates can be predicted with `abc$predict()`.



```{r, echo = T}
abc$predict()
```


Model predictions.

Predictions for the test dataset. Here I can plot the true Y value since we used a simulated observed dataset.


```{r, echo = T}
df_predicted = data.frame(param = rep(colnames(theta), each = nrow(abc$observed)),
                          x = as.numeric(unlist(abc$observed)),
                          y_true = as.numeric(unlist(observed_y)),
                          mean = as.numeric(unlist(abc$predictive_mean)),
                          ci_overall_upper = as.numeric(unlist(abc$CI_overall_upper)),
                          ci_overall_lower = as.numeric(unlist(abc$CI_overall_lower)),
                          ci_e_upper = as.numeric(unlist(abc$CI_epistemic_upper)),
                          ci_e_lower = as.numeric(unlist(abc$CI_epistemic_lower)))


ggplot(data = df_predicted, aes(x = x, y = y_true)) +
  geom_line() +
  geom_line(aes(x = x, y = mean), color = "Red") +
  facet_wrap(~ param, scales = "free") +
  geom_ribbon(aes(x = x, ymin = ci_overall_lower, ymax = ci_overall_upper), alpha = 0.3, fill = "red") +
  geom_ribbon(aes(x = x, ymin = ci_e_lower, ymax = ci_e_upper), alpha = 0.3, fill = "red") +
  theme_bw()
```




```{r, echo = F}
# Plot the simulated data
df_predicted_x1= df_predicted[which(df_predicted$param == "y1"),]
df_predicted_x2 = df_predicted[which(df_predicted$param == "y2"),]

p1 = ggplot(data = df_train, aes(x = x1, y = y1)) +
  geom_point(color = "Blue", alpha = 0.2) +
  geom_line(data = df_test, aes(x = x1, y = y1), color = "black") +
  geom_line(data = df_predicted_x1, aes(x = x, y = mean), color = "red") +
  geom_ribbon(data = df_predicted_x1, aes(x = x, y = mean, ymin = ci_overall_lower, ymax = ci_overall_upper), alpha = 0.3, fill = "red") +
  geom_ribbon(data = df_predicted_x1, aes(x = x, y = mean, ymin = ci_e_lower, ymax = ci_e_upper), alpha = 0.3, fill = "red") +
  theme_bw()

p2 = ggplot(data = df_train, aes(x = x2, y = y2)) +
  geom_point(color = "Green", alpha = 0.2) +
  geom_line(data = df_test, aes(x = x2, y = y2), color = "black") +
  geom_line(data = df_predicted_x2, aes(x = x, y = mean), color = "red") +
  geom_ribbon(data = df_predicted_x2, aes(x = x, y = mean, ymin = ci_overall_lower, ymax = ci_overall_upper), alpha = 0.3, fill = "red") +
  geom_ribbon(data = df_predicted_x2, aes(x = x, y = mean, ymin = ci_e_lower, ymax = ci_e_upper), alpha = 0.3, fill = "red") +
  theme_bw()

ggpubr::ggarrange(p1, p2, ncol = 2)
```




Alternatively you can use the `plot_predicted()` method.


```{r, echo = T}
# predicted (+ C.I.) ~ observed
abc$plot_predicted()
```



To focus on a single prediction, you can look at the distribution of approximate posterior estimates with predictive mean and credible intervals. Compared with prior distribution.


```{r, echo = T}
# Dim 1 is number of MC samples (predictions)
# Dim 2 is number of observations
# Dim 3 is parameters (mu + sigma)
i = 1 # The sample to plot
posteriors = abc$posterior_samples[,i,]
# output_names = unlist(lapply(c("mu", "sigma"), function(x) paste(colnames(theta), x, sep = "_")))
posteriors = as.data.frame(posteriors)
posteriors = posteriors[,1:abc$output_dim]
colnames(posteriors) = colnames(abc$theta)
posteriors$mc_sample = as.character(c(1:nrow(posteriors)))

tidy_df = posteriors %>% tidyr::gather(param, prediction, any_of(colnames(abc$theta)))
# tidy_df

tidy_predictions = data.frame(param = colnames(abc$theta),
                              mean = as.numeric(abc$predictive_mean[i,]),
                              ci_lower = as.numeric(abc$CI_overall_lower[i,]),
                              ci_upper = as.numeric(abc$CI_overall_upper[i,]),
                              ci_e_lower = as.numeric(abc$CI_epistemic_lower[i,]),
                              ci_e_upper = as.numeric(abc$CI_epistemic_upper[i,]))
# tidy_predictions


# abc$theta
tidy_priors = data.frame(param = rep(colnames(abc$theta), each = nrow(abc$theta)),
                         prior = as.numeric(unlist(abc$theta)))
# tidy_priors

cols = c("Epistemic"="#D55E00","Overall"="#0072B2")

ggplot() +
  geom_histogram(data = tidy_priors, aes(x = prior), color = "darkgrey", fill = "grey", alpha = 0.1) +
  geom_histogram(data = tidy_df, aes(x = prediction)) +
  geom_vline(data = tidy_predictions, aes(xintercept = mean, colour = "Epistemic")) +
  geom_rect(data = tidy_predictions, aes(xmin = ci_e_lower, xmax = ci_e_upper, ymin = -Inf, ymax = Inf, colour = "Epitstemic", fill = "Epistemic"), alpha = 0.2) +
  geom_vline(data = tidy_predictions, aes(xintercept = ci_e_lower, colour = "Epistemic")) +
  geom_vline(data = tidy_predictions, aes(xintercept = ci_e_upper, colour = "Epistemic")) +
  geom_vline(data = tidy_predictions, aes(xintercept = ci_lower, colour = "Overall")) +
  geom_vline(data = tidy_predictions, aes(xintercept = ci_upper, colour = "Overall")) +
  geom_rect(data = tidy_predictions, aes(xmin = ci_lower, xmax = ci_upper, ymin = -Inf, ymax = Inf, colour = "Overall", fill = "Overall"), alpha = 0.2) +
  facet_wrap(~ param, scales = "free") +
  scale_colour_manual(name = "Uncertainty", values = cols) +
  scale_fill_manual(name = "Uncertainty", values = cols) +
  xlab("Value") + ylab("Count") +
  theme_bw() +
  theme(legend.position = "right")
```


Try to compare a prediction within the training data with a prediction out of prior distribution. See the effect of random noise or out of distribution on uncertainty.


```{r, echo = T}
# Print a sample with -5 < x1 < -4 (within the distribution with a low noise)
# which(abc$observed < -4 & abc$observed > -5)
abc$plot_posterior(sample = 155, prior = TRUE)

# Print a sample with 4 < x1 < 5 (within the distribution with a high noise)
# which(abc$observed < 5 & abc$observed > 4)
abc$plot_posterior(sample = 800, prior = TRUE)

# Print a sample with -1 < x1 < 1 (out of training distribution)
# which(abc$observed < 1 & abc$observed > -1)
abc$plot_posterior(sample = 520, prior = TRUE)
```




## Deep Ensemble prediction







## Apply to infer population genetics parameters

Simulations with `msprime`.

Reference table (simulations summary stats) and priors.


```{r, echo = T}
# Import the reference table and other data
sumstats = read.table("../inst/extdata/reference_table.csv",
                             sep = "\t", header = T, row.names = NULL)

ncol(sumstats)
colnames(sumstats)

row.names(sumstats) = sumstats$sample
sumstats = sumstats[,-1]
colnames(sumstats)[1]

theta_sim = read.table("../inst/extdata/theta_simulations.csv",
                    sep = "\t", header = T, fill = TRUE)
head(theta_sim)
row.names(theta_sim) = theta_sim$sample
theta_sim = theta_sim[,-1]
colnames(theta_sim)[1]

# Check consistency between priors and reference table
nrow(sumstats) == nrow(theta_sim)
sum(row.names(sumstats) == row.names(theta_sim)) == nrow(theta_sim)


# Split datasets
# Two parameters, t1 and t2
idx_training = c(1:39000)
idx_observed = c(39001:40000)

theta_training = theta_sim[idx_training,c("t1", "t2")]
theta_observed = theta_sim[idx_observed,c("t1", "t2")]

sumstats_training = sumstats[idx_training,]
sumstats_observed = sumstats[idx_observed,]

# colnames(theta_training)
```




