---
title: "model_inference"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{model_inference}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
# library(abcneuralnet)
devtools::load_all()
library(ggplot2)
library(torch)
```


## Basic Bayesian Neural Network inference


### Toy dataset - a simple linear regression problem


```{r, echo = T}
n_train = 2000 # Number of data points
n_obs = 1000 # Validation size

gen_data_1d = function(n) {
  sigma = 1
  X = matrix(rnorm(n))
  w = 2
  b = 8
  Y = matrix(X %*% w + b + sigma * rnorm(n))
  list(X = X, Y = Y)
}

XY = gen_data_1d(n_train + n_obs)

X_train = XY$X[1:n_train]
Y_train = XY$Y[1:n_train]

X_obs = XY$X[(n_train + 1):(n_train + n_obs)]
Y_obs = XY$Y[(n_train + 1):(n_train + n_obs)]

# Predict Y when X is observed
theta = data.frame(y1 = Y_train)
sumstats = data.frame(x1 = X_train)
observed = data.frame(X1 = X_obs)
```

### Fit a model with `abcnn`

We use a Concrete Dropout regression model described in [ref]. See https://blogs.rstudio.com/ai/posts/2018-11-12-uncertainty_estimates_dropout/ for more details.


```{r, echo = T}
# Init an abcnn object with inputs and targets
abc = abcnn$new(theta,
            sumstats,
            observed,
            method = 'concrete dropout',
            scale_input = "none",
            scale_target = "none",
            num_hidden_layers = 3,
            num_hidden_dim = 256,
            epochs = 30,
            batch_size = 32,
            l2_weight_decay = 1e-5)


abc$summary()

# Plot simulation distribution and observed data points
# abc$plot_lda()
```

The `abcnn` object is a `R6Class` object.
Modern implementation, OOP


For example, the fitted model can be accessed with `abc$model`.


The model is trained by calling `abc$fit()`.


```{r, echo = T}
# Use the fit() method to train the neural network
abc$fit()
```

Note that sometimes the heteroscedastic loss value can be negative, but it does not impact the training procedure.

Check model fit.

```{r, echo = T}
# Check the fit of the model
as.numeric(unlist(abc$fitted$records$metrics$train))
as.numeric(unlist(abc$fitted$records$metrics$valid))
abc$eval_metrics

# The dropout rate
abc$dropout_rates # Not yet implemented

# The distribution of weights
hist(as.numeric(abc$fitted$model$parameters$concrete_dropout.conc_drop1.linear.weight))
hist(as.numeric(abc$fitted$model$parameters$concrete_dropout.conc_drop2.linear.weight))
hist(as.numeric(abc$fitted$model$parameters$concrete_dropout.conc_drop3.linear.weight))
```



Plot the training curve. The black horizontal line is the loss computed on the test dataset.


```{r, echo = T}
train_metric = as.numeric(unlist(abc$fitted$records$metrics$train))
valid_metric = as.numeric(unlist(abc$fitted$records$metrics$valid))
eval = abc$eval_metrics$value


train_eval = data.frame(Epoch = rep(1:length(train_metric), 2),
                        Metric = c(train_metric, valid_metric),
                        Mode = c(rep("train", length(train_metric)), rep("validation", length(valid_metric))))

ggplot(train_eval, aes(x = Epoch, y = Metric, color = Mode, fill = Mode)) +
  geom_point() +
  geom_line() +
  xlab("Epoch") + ylab("Loss") +
  geom_hline(yintercept = eval) +
  theme_bw()
```



```{r, echo = T}
abc$plot_training()
```





Save the `abccn` object with the fitted model.


```{r, echo = T}
# save_abcnn(abc, prefix = "../inst/extdata/abc_concrete")
# 
# abc = load_abcnn(prefix = "../inst/extdata/abc_concrete")
```





### Predicting parameters with the Concrete Dropout method


After the model is trained, parameter estimates can be predicted with `abc$predict()`.



```{r, echo = T}
abc$predict()
```


Model predictions.

```{r, echo = T}
# Return a tidy data frame
head(abc$predictions())
```



Predictions for the test dataset. Here I can plot the true Y value since we used a simulated observed dataset.


```{r, echo = T}
df_predicted = abc$predictions()

df_predicted$ci_overall_upper = df_predicted$predictive_mean + df_predicted$overall_uncertainty
df_predicted$ci_overall_lower = df_predicted$predictive_mean - df_predicted$overall_uncertainty

df_predicted$ci_e_upper = df_predicted$predictive_mean + df_predicted$epistemic_uncertainty
df_predicted$ci_e_lower = df_predicted$predictive_mean - df_predicted$epistemic_uncertainty

df_predicted$ci_conformal_upper = df_predicted$predictive_mean + df_predicted$overall_conformal_credible_interval
df_predicted$ci_conformal_lower = df_predicted$predictive_mean - df_predicted$overall_conformal_credible_interval

df_predicted$ci_conformal_e_upper = df_predicted$predictive_mean + df_predicted$epistemic_conformal_credible_interval
df_predicted$ci_conformal_e_lower = df_predicted$predictive_mean - df_predicted$epistemic_conformal_credible_interval

df_predicted$x = X_obs
df_predicted$y_true = Y_obs

df_training = data.frame(x = X_train,
                         y = Y_train)
```

```{r, echo = T}
ggplot(data = df_training, aes(x = x, y = y)) +
  geom_point(color = "blue", alpha = 0.3) +
  # geom_point(data = df_predicted, aes(x = x, y = y_true), color = "green", alpha = 0.3) +
  geom_line(data = df_predicted, aes(x = x, y = predictive_mean), color = "Red") +
  geom_point(data = df_predicted, aes(x = x, y = predictive_mean), color = "Red") +
  facet_wrap(~ parameter, scales = "free") +
  geom_ribbon(data = df_predicted, aes(x = x, y = predictive_mean, ymin = ci_conformal_e_upper, ymax = ci_conformal_e_lower), alpha = 0.4, fill = "purple") +
  geom_ribbon(data = df_predicted, aes(x = x, y = predictive_mean, ymin = ci_conformal_upper, ymax = ci_conformal_lower), alpha = 0.3, fill = "green") +
  theme_bw()
```

```{r, echo = T}
ggplot(data = df_training, aes(x = x, y = y)) +
  geom_point(color = "blue", alpha = 0.3) +
  # geom_point(data = df_predicted, aes(x = x, y = y_true), color = "green", alpha = 0.3) +
  geom_line(data = df_predicted, aes(x = x, y = predictive_mean), color = "Red") +
  geom_point(data = df_predicted, aes(x = x, y = predictive_mean), color = "Red") +
  facet_wrap(~ parameter, scales = "free") +
  geom_ribbon(data = df_predicted, aes(x = x, y = predictive_mean, ymin = ci_overall_lower, ymax = ci_overall_upper), alpha = 0.3, fill = "red") +
  geom_ribbon(data = df_predicted, aes(x = x, y = predictive_mean, ymin = ci_e_lower, ymax = ci_e_upper), alpha = 0.3, fill = "red") +
  theme_bw()
```


Alternatively you can use the `plot_predicted()` method.


```{r, echo = T}
# predicted (+ C.I.) ~ observed
abc$plot_predicted(paired = TRUE, type = "uncertainty")

abc$plot_predicted(paired = TRUE, type = "conformal")

abc$plot_predicted(paired = TRUE, type = "posterior quantile")
```



To focus on a single prediction, you can look at the distribution of approximate posterior estimates with predictive mean and credible intervals. Compared with prior distribution.



Try to compare a prediction within the training data with a prediction out of prior distribution. See the effect of random noise or out of distribution on uncertainty.


```{r, echo = T}
# Print a sample with -5 < x1 < -4 (within the distribution with a low noise)
# which(abc$observed$X1 < 2 & abc$observed > -2)
abc$plot_posterior(sample = 501, prior = TRUE, type = "conformal") +
  geom_vline(xintercept = Y_obs[501], color = "red", size = 1.5)
Y_obs[501]
abc$predictive_mean$y1[501]

# Print a sample out of distribution
# which(abc$observed$X1 > 7)
abc$plot_posterior(sample = 735, prior = TRUE, type = "conformal") +
  geom_vline(xintercept = Y_obs[735], color = "red", size = 1.5)
Y_obs[735]
abc$predictive_mean$y1[735]
```


```{r, echo = T}
# Print a sample with -5 < x1 < -4 (within the distribution with a low noise)
# which(abc$observed$X1 < 2 & abc$observed > -2)
abc$plot_posterior(sample = 501, prior = TRUE, type = "uncertainty") +
  geom_vline(xintercept = Y_obs[501], color = "red", size = 1.5)
Y_obs[501]
abc$predictive_mean$y1[501]

# Print a sample out of distribution
# which(abc$observed$X1 > 7)
abc$plot_posterior(sample = 735, prior = TRUE, type = "uncertainty") +
  geom_vline(xintercept = Y_obs[735], color = "red", size = 1.5)
Y_obs[735]
abc$predictive_mean$y1[735]
```



## Deep Ensemble prediction


### A more complex relationship (sinus and cosinus functions)

Two parameters to estimate.

Simulate two different functions (sin and cos), with missing data (gaps) and different amounts of random noise in the two parts of the dataset.

```{r, echo = T}
# Parameters of simulated input x
data_range = 7
data_step = 0.0005

# Boundaries of the gap in the data range
bound1 = -2
bound2 = 2

# Random noise applied on y
data_sigma1a = 0.1
data_sigma2a = 0.5

data_sigma1b = 0.2
data_sigma2b = 0.1

# Number of simulated data points
# num_data = 10000

# Simulate x1
data_x1a = seq(-data_range, bound1 + data_step, by = data_step)
data_x1b = seq(bound2, data_range + data_step, by = data_step)
# Simulate targets y
data_y1a = sin(data_x1a) + rnorm(length(data_x1a), 0, data_sigma1a)
data_y1b = sin(data_x1b) + rnorm(length(data_x1b), 0, data_sigma2a)

# Shift X1 to get X2
data_x2a = data_x1a + 7
data_x2b = data_x1b + 7
# Simulate targets y
data_y2a = cos(data_x2a) + rnorm(length(data_x2a), 0, data_sigma1b)
data_y2b = cos(data_x2b) + rnorm(length(data_x2b), 0, data_sigma2b)

df = data.frame(x1 = c(data_x1a, data_x1b),
                    x2 = c(data_x2a, data_x2b),
                    y1 = c(data_y1a, data_y1b),
                    y2 = c(data_y2a, data_y2b))

# Shuffle data
shuffle_idx = sample(1:(nrow(df)), nrow(df), replace = FALSE)
df_train = df[shuffle_idx,]

# Train/Test datasets
# test_ratio = 0.1
# num_train_data = round(nrow(df) * (1 - test_ratio), digits = 0)
# num_test_data  = nrow(df) - num_train_data
# 
# train_x = df[1:num_train_data, c("x1", "x2")]
# train_y = df[1:num_train_data, c("y1", "y2")]
# test_x = df[num_train_data:nrow(df_train), c("x1", "x2")]
# test_y = df[num_train_data:nrow(df_train), c("y1", "y2")]
train_x = df_train[, c("x1", "x2")]
train_y = df_train[, c("y1", "y2")]


# Make a pseudo-obseerved dataset with out of distribution data points
# Simulate x1
data_x1 = seq(-data_range, data_range, length.out = 1000)
# Simulate true targets y
data_y1 = sin(data_x1)

# Shift X1 to get X2
data_x2 = data_x1 + 7
# Simulate targets y
data_y2 = cos(data_x2)

df_observed = data.frame(x1 = data_x1,
                x2 = data_x2,
                y1 = data_y1,
                y2 = data_y2)


observed_x  = df_observed[, c("x1", "x2")]
observed_y  = df_observed[, c("y1", "y2")]
```


```{r, echo = F}
# Plot the simulated data
p1 = ggplot(data = df_train, aes(x = x1, y = y1)) +
  geom_point(color = "Blue", alpha = 0.2) +
  geom_line(data = df_observed, aes(x = x1, y = y1), color = "red") +
  theme_bw()

p2 = ggplot(data = df_train, aes(x = x2, y = y2)) +
  geom_point(color = "Green", alpha = 0.2) +
  geom_line(data = df_observed, aes(x = x2, y = y2), color = "red") +
  theme_bw()

ggpubr::ggarrange(p1, p2, ncol = 2)
```




### Fit a Deep Ensemble network

Train five networks with the Deep Ensemble algorithm and adversarial training.

Try with a single parameter to estimate first.


```{r, echo = T}
# Predict Y when X is observed
theta = data.frame(y = train_y$y1)
sumstats = data.frame(x = train_x$x1)
observed = data.frame(x = observed_x$x1)

abc_ensemble = abcnn$new(theta,
            sumstats,
            observed,
            method = 'deep ensemble',
            scale_input = "none",
            scale_target = "none",
            num_networks = 5,
            epochs = 30,
            num_hidden_layers = 3,
            num_hidden_dim = 512,
            batch_size = 32,
            epsilon_adversarial = NULL)
```

```{r, echo = T}
abc_ensemble$fit()
```



```{r, echo = T}
# save_abcnn(abc_ensemble, prefix = "../inst/extdata/abc_ensemble")
# 
# abc_ensemble = load_abcnn(prefix = "../inst/extdata/abc_ensemble")
```




```{r, echo = T}
abc_ensemble$plot_training()
```




````{r, echo = T}
abc_ensemble$predict()
```


```{r, echo=T}
abc_ensemble$plot_predicted(paired = TRUE, type = "conformal") +
  geom_point(data = df_train, aes(x = x1, y = y1), color = "blue", alpha = 0.01)
```



For Deep Ensemble, there are no posterior samples to plot with the `plot_posterior` method as in Monte Carlo dropout or Concrete Dropout. But it is still interesting to check a single prediction with its uncertainty within or without training distribution.

```{r, echo = T}
# Print a sample with -5 < x1 < -4 (within the distribution with a low noise)
# which(abc$observed < -4 & abc$observed > -5)
abc_ensemble$plot_posterior(sample = 155, prior = TRUE) +
  geom_vline(aes(xintercept = observed_y$y1[155]), color = "red")

# Print a sample with 4 < x1 < 5 (within the distribution with a high noise)
# which(abc$observed < 5 & abc$observed > 4)
abc_ensemble$plot_posterior(sample = 800, prior = TRUE) +
  geom_vline(aes(xintercept = observed_y$y1[800]), color = "red")

# Print a sample with -1 < x1 < 1 (out of training distribution)
# which(abc$observed < 1 & abc$observed > -1)
abc_ensemble$plot_posterior(sample = 520, prior = TRUE) +
  geom_vline(aes(xintercept = observed_y$y1[520]), color = "red")
```



## Multi parameter inference

And for two parameters jointly estimated?



```{r, echo = T}
# devtools::load_all()
# Predict Y when X is observed
theta = train_y
sumstats = train_x
observed = observed_x

abc_ensemble = abcnn$new(theta,
            sumstats,
            observed,
            method = 'deep ensemble',
            num_networks = 5,
            scale_input = "none",
            scale_target = "none",
            epochs = 30,
            num_hidden_layers = 3,
            num_hidden_dim = 512,
            batch_size = 32,
            epsilon_adversarial = 0.01)
```


```{r, echo = T}
abc_ensemble$fit()
```



```{r, echo = T}
# save_abcnn(abc_ensemble, prefix = "../inst/extdata/abc_ensemble_2param")
# 
# abc_ensemble = load_abcnn(prefix = "../inst/extdata/abc_ensemble_2param")
```




```{r, echo = T}
abc_ensemble$plot_training()
```




````{r, echo = T}
abc_ensemble$predict()
```


````{r, echo = T}
abc_ensemble$plot_predicted(paired = TRUE, type = "conformal")
```




```{r, echo = T}
# Print a sample with -5 < x1 < -4 (within the distribution with a low noise)
# which(abc$observed < -4 & abc$observed > -5)
abc_ensemble$plot_posterior(sample = 155, prior = TRUE)

# Print a sample with 4 < x1 < 5 (within the distribution with a high noise)
# which(abc$observed < 5 & abc$observed > 4)
abc_ensemble$plot_posterior(sample = 800, prior = TRUE)

# Print a sample with -1 < x1 < 1 (out of training distribution)
# which(abc$observed < 1 & abc$observed > -1)
abc_ensemble$plot_posterior(sample = 520, prior = TRUE)
```



## Train with Tabnet-ABC

### Normal Toy model


```{r}
########################################################
#               Simulation of                          #
#           a Gaussian toy example                     #
########################################################

library(doParallel) # for parallel computing
library(mvtnorm) # for multivariate normal distribution
library(spatstat) # for weighted.quantile function
library(MCMCpack) # for the inverse gamma distribution

#====================================
# Homoscedastic Normal toy model
#====================================
# Sample size of y
n = 10
# Inverse gamma parameters
alpha = 4
beta = 3
# Training set sample size
N = 10000
# Test set sample size
p = 100
# offset for the out-of-dist data
offset = 0

homoscedastic_normal = function(alpha = 4,
                                beta = 3,
                                n = 10,
                                N = 10000,
                                p = 1000,
                                offset = 0) {
  # Function to compute quantiles from
  # student distribution
  qnst = function(p, deg, loca, scale) {
    return(loca + scale * qt(p, df = deg))
  }
  
  # Simulation of the ABC reference table
  
  set.seed(1) # for reproducibility 
  
  # X parameter
  theta1.train = rep(NA, N)
  theta2.train = 1 / rgamma(N, shape = alpha, rate = beta)
  for (i in 1:N) {
    theta1.train[i] = rnorm(1, 0, sqrt(theta2.train[i]))
  }
  
  # Add offset for out of dist
  theta2.train = theta2.train + offset
  theta1.train = theta1.train + offset
  
  # Y parameter
  # n sample cols
  # n training set rows
  y.ref = matrix(NA, N, n)
  for (i in 1:N) {
    y.ref[i, ] = rnorm(n, theta1.train[i], sqrt(theta2.train[i]))
  }
  
  # Compute some summary statistics 
  sumstats.train = matrix(NA, N, 3)
  
  for (i in 1:N) {
    sumstats.train[i, ] = c(mean(y.ref[i, ]), var(y.ref[i, ]), mad(y.ref[i, ]))
  }
  
  ref.training = cbind(theta1.train, theta2.train, sumstats.train)
  colnames(ref.training) = c("theta1", "theta2", "expectation", "variance", "mad")
  
  # Simulation of the ABC test table
  theta1.test = rep(NA, p)
  
  theta2.test = 1 / rgamma(p, shape = alpha, rate = beta)
  for (i in 1:p) {
    theta1.test[i] = rnorm(1, 0, sqrt(theta2.test[i]))
  }
  
  theta2.test = theta2.test + offset
  theta1.test = theta1.test + offset
  
  y.test = matrix(NA, p, n)
  
  for (i in 1:p) {
    y.test[i, ] = rnorm(n, theta1.test[i], sqrt(theta2.test[i]))
  }
  
  # Compute some summary statistics
  sumstats.test = matrix(NA, p, 3)
  
  for (i in 1:p) {
    sumstats.test[i, ] =
      c(mean(y.test[i, ]), var(y.test[i, ]), mad(y.test[i, ]))
  }
  
  ref.testing = cbind(theta1.test, theta2.test, sumstats.test)
  colnames(ref.testing) = c("theta1", "theta2", "expectation", "variance", "mad")
  
  
  # Compute the exact posterior expectations, variances and quantiles 
  # for parameters theta1 and theta2
  theta1.test.exact = rep(NA, p)
  theta2.test.exact = rep(NA, p)
  var1.test.exact = rep(NA, p)
  var2.test.exact = rep(NA, p)
  quant.theta1.test.freq = matrix(NA, p, 2)
  quant.theta2.test.freq = matrix(NA, p, 2)
  
  for (i in 1:p) {
    theta1.test.exact[i] = sum(y.test[i, ]) / (n + 1)
    var1.test.exact[i] =
      (beta + sum((y.test[i, ] - mean(y.test[i, ])) ^ 2)/2 + n*(mean(y.test[i, ]))^2 / (2*(n+1))  ) /
      ( (n + 1) * (alpha - 1 + n / 2) )
    theta2.test.exact[i] =
      (beta + sum((y.test[i, ] - mean(y.test[i, ])) ^ 2)/2 + n*(mean(y.test[i, ]))^2 / (2*(n+1))  ) / (alpha - 1 + n / 2)
    var2.test.exact[i] =
      (beta + sum((y.test[i, ] - mean(y.test[i, ])) ^ 2)/2 + n*(mean(y.test[i, ]))^2 / (2*(n+1))  ) ^ 2 / ((alpha - 1 + n / 2) ^ 2 * (alpha - 2 + n / 2))
    quant.theta1.test.freq[i, ] =
      c(qnst(0.025, n + 2 * alpha, sum(y.test[i, ]) / (n + 1), sqrt(2 * (beta + sum((y.test[i, ] - mean(y.test[i, ])) ^ 2)/2 + n*(mean(y.test[i, ]))^2 / (2*(n+1))  ) / ((n + 1) * (n + 2 * alpha) ))),
        qnst(0.975, n + 2 * alpha, sum(y.test[i, ]) / (n + 1), sqrt(2 * (beta + sum((y.test[i, ] - mean(y.test[i, ])) ^ 2)/2 + n*(mean(y.test[i, ]))^2 / (2*(n+1))  ) / ((n + 1) * (n + 2 * alpha) ))))
    quant.theta2.test.freq[i, ] = 
      c(1 / qgamma(0.975, shape = (n + 2 * alpha) / 2, rate = (beta + sum((y.test[i, ] - mean(y.test[i, ])) ^ 2)/2 + n*(mean(y.test[i, ]))^2 / (2*(n+1))  ) ),
        1 / qgamma(0.025, shape = (n + 2 * alpha) / 2, rate = (beta + sum((y.test[i, ] - mean(y.test[i, ])) ^ 2)/2 + n*(mean(y.test[i, ]))^2 / (2*(n+1))  )) )
  }
  
  test.exact = data.frame(mean.theta1 = theta1.test.exact,
                          var.theta1 = var1.test.exact,
                          lower.theta1 = quant.theta1.test.freq[,1],
                          upper.theta1 = quant.theta1.test.freq[,2],
                          mean.theta2 = theta2.test.exact,
                          var.theta2 = var2.test.exact,
                          lower.theta2 = quant.theta2.test.freq[,1],
                          upper.theta2 = quant.theta2.test.freq[,2])
  
  # Add noise to summary statistics simulated according 
  # to a uniform(0,1) distribution
  nNoise = 50 # or 500
  
  set.seed(3)  # for reproducibility 
  
  sumstats.noise = matrix(runif((N+p) * nNoise), N+p, nNoise) 
  ref.training = cbind(ref.training, sumstats.noise[1:N, ])
  ref.testing = cbind(ref.testing, sumstats.noise[(N+1):(N+p), ])
  
  colnames(ref.training) =
    c("theta1", "theta2", "expectation", "variance", "mad", c(1:nNoise))
  colnames(ref.testing) =
    c("theta1", "theta2", "expectation", "variance", "mad", c(1:nNoise))
  
  # Add some others summary statistics 
  y = ref.training[, 1:2]
  x = ref.training[, -c(1:2)]
  
  x =cbind(x, x[, 1] + x[, 2], x[, 1] + x[, 3], x[, 2] + x[, 3], x[, 1] + x[, 2] +
             x[, 3], x[, 1] * x[, 2], x[, 1] * x[, 3], x[, 2] * x[, 3], x[, 1] * x[, 2] *
             x[, 3])
  colnames(x) =
    c("expectation",
      "variance",
      "mad",
      c(1:nNoise),
      "sum_esp_var",
      "sum_esp_mad" ,
      "sum_var_mad",
      "sum_esp_var_mad",
      "prod_esp_var",
      "prod_esp_mad",
      "prod_var_mad" ,
      "prod_esp_var_mad")
  
  ytest = ref.testing[, 1:2]
  xtest = ref.testing[, -c(1:2)]
  
  xtest =
    cbind(
      xtest,
      xtest[, 1] + xtest[, 2],
      xtest[, 1] + xtest[, 3],
      xtest[, 2] + xtest[, 3],
      xtest[, 1] + xtest[, 2] + xtest[, 3],
      xtest[, 1] * xtest[, 2],
      xtest[, 1] * xtest[, 3],
      xtest[, 2] * xtest[, 3],
      xtest[, 1] * xtest[, 2] * xtest[, 3]
    )
  colnames(xtest) =
    c("expectation",
      "variance",
      "mad",
      c(1:nNoise),
      "sum_esp_var",
      "sum_esp_mad" ,
      "sum_var_mad",
      "sum_esp_var_mad",
      "prod_esp_var",
      "prod_esp_mad",
      "prod_var_mad" ,
      "prod_esp_var_mad")
  
  data.theta1 = data.frame(theta1 = y[,1], x)
  data.theta2 = data.frame(theta2 = y[,2], x)
  
  param.Test = data.frame(ytest)
  
  colnames(param.Test) = c("theta1", "theta2")
  
  stats.Test = data.frame(xtest)
  
  colnames(stats.Test) = colnames(x)
  colnames(param.Test) = colnames(y)
  
  return(list(x.train = x,
              y.train = y,
              x.test = stats.Test,
              y.test = param.Test,
              y.exact = test.exact))
}


dataset = homoscedastic_normal()

# To train
sumstats.train = as.data.frame(dataset$x.train)
theta.train = as.data.frame(dataset$y.train)

# To test
sumstats.test = dataset$x.test
theta.test = dataset$y.test
```


```{r}
colnames(theta.train)
ggplot(theta.train, aes(x = theta1, y = theta2)) +
  geom_point() +
  geom_point(data = theta.test, aes(x = theta1, y = theta2), color = "red", alpha = 0.5)

```

### Fit and predict with Tabnet-ABC


```{r}
tabnetabc = abcnn$new(theta.train,
            sumstats.train,
            sumstats.test[1:1000,],
            method = 'tabnet-abc',
            scale_input = "normalization",
            scale_target = "none",
            epochs = 30,
            batch_size = 128,
            l2_weight_decay = 1e-3,
            tol = 0.1,
            abc_method = "loclinear")


tabnetabc$summary()
```



````{r}
tabnetabc$fit()

tabnetabc$plot_training()
```

```{r}
tabnetabc$predict()
```


```{r}
tabnetabc$plot_predicted(type = "posterior quantile")
```


```{r}
tabnetabc$plot_posterior(5, type = "posterior quantile")
```


```{r}
df = tabnetabc$predictions() %>%
  filter(parameter == "theta1")

df$true.theta = theta.test[1:1000,"theta1"]

ggplot(df, aes(x = true.theta, y = predictive_mean)) +
  geom_ribbon(aes(ymin = posterior_lower_ci, ymax = posterior_upper_ci), colour = "lightgrey", alpha = 0.5) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_bw()
```




