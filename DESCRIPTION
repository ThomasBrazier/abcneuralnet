Package: abcneuralnet
Title: Bayesian Deep Learning and Approximate Bayesian Computation for parameter inference
Version: 0.0.0.9000
Authors@R: 
    person("Brazier", "Thomas", , "brazier.thomas@gmail.com", role = c("aut", "cre"))
Author: Thomas Brazier [aut, cre]
Maintainer: Thomas Brazier <brazier.thomas@gmail.com>
Description:
  This package is designed for parameter inference with ABC and neural networks for population genetics.
  It implements four different methods mixing ABC and neural networks implemented in R `torch`.
  The two core methods are `concrete dropout`,
  an implementation of Gal et al. (2017), and `deep ensemble`, an implementation
  of Lakshminarayanan et al. (2017), both allowing to estimate both the aleatoric and epistemic uncertainty
  for each sample. `monte carlo dropout` is an implementation of Gal and Ghahramani (2016),
  that provides a simpler model easier to train, despite its limitations (the dropout rate must be arbitrary chosen).
  A fourth method is `tabnet-abc`. This is a new method, combining regular ABC inference with the `abc` R package,
  and a Tabnet neural network, as in Arik et al. (2021) and implemented in the `tabnet` R package.
  This is the same idea than in Ã…kesson et al. (2021) or Jiang et al. (2017), except than te MLP/CNN used to estimate summary statistics
  is replaced by a `tabnet` model specifically designed to handle tabular data and feature selection through
  an attention map on features. The `tabnet` neural network is trained to predict summary statistics from the observed summary statistics.
  Then these predictions are used as a supplementary set of summary statistics and regular ABC inference is performed on it.
  Explain methods are specific the `tabnet-abc` model.
  In addition, the credible interval is calibrated with conformal prediction, as in Baragatti et al. (2024).
  As it requires a proxy of uncertainty, conformal prediction is only available for `concrete dropout`,
  `deep ensemble` and `monte carlo dropout` (only for the epistemic uncertainty for this last method).
  The neural networks are implemented with the `torch` R package and support CUDA devices for training.
  The `luz` package is used as a higher level API for training and predictions with `torch`.
  The device (`CUDA` or `cpu`) is automatically detected by `luz`.
License: GPL (>= 3)
Encoding: UTF-8
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.3.2
Suggests: 
    knitr,
    rmarkdown,
    testthat (>= 3.0.0)
Imports:
    R6,
    RColorBrewer,
    Rdpack,
    knitr,
    abc,
    bundle,
    dplyr,
    ggplot2,
    ggpubr,
    innsight,
    janitor,
    luz,
    plotly,
    tabnet,
    tibble,
    tidyr,
    torch,
    devtools,
    assertthat,
    here
VignetteBuilder: knitr
RdMacros: Rdpack
Config/testthat/edition: 3
